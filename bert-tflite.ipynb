{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41daad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3755fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load TFLite Model and Tokenizer ---\n",
    "print(\"Loading TFLite model and tokenizer...\")\n",
    "interpreter = tf.lite.Interpreter(model_path=\"/home/kronbii/Downloads/toxic_bert_dynamic.tflite\")\n",
    "model_name = \"unitary/toxic-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(\"Model and tokenizer loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Configure TFLite Interpreter for Single Sentence Inference ---\n",
    "# We will process one sentence at a time, so we set the input shape to [1, 128] once.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Get the index for each input tensor by name\n",
    "input_ids_index = next(i['index'] for i in input_details if 'input_ids' in i['name'])\n",
    "attention_mask_index = next(i['index'] for i in input_details if 'attention_mask' in i['name'])\n",
    "\n",
    "# Define the fixed input shape [batch_size=1, sequence_length=128]\n",
    "input_shape = [1, 128]\n",
    "\n",
    "# Resize both input tensors for a single sentence\n",
    "interpreter.resize_tensor_input(input_ids_index, input_shape)\n",
    "interpreter.resize_tensor_input(attention_mask_index, input_shape)\n",
    "\n",
    "# Allocate tensors ONCE before the loop\n",
    "interpreter.allocate_tensors()\n",
    "print(\"\\n‚úÖ TFLite interpreter configured for single sentence inference (shape [1, 128]).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Load and Prepare Dataset ---\n",
    "print(\"\\nLoading and cleaning dataset...\")\n",
    "try:\n",
    "    input_df = pd.read_csv(\"/home/kronbii/repos/content-violence-detection/datasets/text/jigsaw/test.csv\")\n",
    "    gt_df = pd.read_csv(\"/home/kronbii/repos/content-violence-detection/datasets/text/jigsaw/test_labels.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset files not found. Please update the file paths.\")\n",
    "    exit()\n",
    "\n",
    "# Merge on 'id' to align text with labels\n",
    "data = input_df.merge(gt_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "# Define the label columns\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Remove rows where any label is -1 (samples not used for scoring)\n",
    "clean_data = data[~(data[label_cols] == -1).any(axis=1)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Rows before cleaning: {len(data)}\")\n",
    "print(f\"Rows after removing rows with -1 labels: {len(clean_data)}\")\n",
    "print(\"Dataset ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Run Sentence-by-Sentence Inference ---\n",
    "print(\"\\nRunning inference sentence by sentence...\")\n",
    "\n",
    "# Store predictions\n",
    "all_preds = []\n",
    "texts = clean_data['comment_text'].tolist()\n",
    "ids = clean_data['id'].tolist()\n",
    "\n",
    "# Loop through each sentence individually\n",
    "for sentence in tqdm(texts, desc=\"Processing Sentences\"):\n",
    "    # Tokenize the single sentence\n",
    "    inputs = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"tf\", # Return TensorFlow tensors\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    # Set the input tensor values\n",
    "    interpreter.set_tensor(input_ids_index, inputs['input_ids'])\n",
    "    interpreter.set_tensor(attention_mask_index, inputs['attention_mask'])\n",
    "\n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output, apply sigmoid\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    # The output shape is (1, 6), so we get the first element for our 1D probability array\n",
    "    probs = tf.nn.sigmoid(output_data).numpy()[0]\n",
    "    all_preds.append(probs)\n",
    "\n",
    "# Combine the list of 1D arrays into a 2D numpy array\n",
    "all_preds = np.array(all_preds)\n",
    "\n",
    "# Build the output DataFrame\n",
    "pred_df = pd.DataFrame(all_preds, columns=label_cols)\n",
    "pred_df.insert(0, 'id', ids)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "pred_df.to_csv(\"tflite_text_jigsaw.csv\", index=False)\n",
    "print(\"TFLite predictions saved to tflite_predictions_sentence_by_sentence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4350299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Evaluate Performance ---\n",
    "print(\"\\nEvaluating performance...\")\n",
    "\n",
    "# Get the ground truth labels\n",
    "y_true = clean_data[label_cols].values\n",
    "# Get the predicted probabilities\n",
    "y_pred_probs = pred_df[label_cols].values\n",
    "\n",
    "# Binarize predictions using a 0.5 threshold\n",
    "y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nüîç Per-label Evaluation:\\n\")\n",
    "for i, label in enumerate(label_cols):\n",
    "    true = y_true[:, i]\n",
    "    pred = y_pred[:, i]\n",
    "\n",
    "    acc = accuracy_score(true, pred)\n",
    "    f1 = f1_score(true, pred, average='binary', zero_division=0)\n",
    "\n",
    "    print(f\"Label: {label.capitalize()}\")\n",
    "    print(f\"  Accuracy:          {acc:.4f}\")\n",
    "    print(f\"  F1 Score:          {f1:.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
