{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec2c51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 13:34:06.660557: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-16 13:34:06.660679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-16 13:34:06.690654: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-16 13:34:06.757620: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-16 13:34:08.222990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c46221cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 13:34:21.507688: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-16 13:34:21.514092: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "2025-08-16 13:34:22.305671: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2025-08-16 13:34:22.428060: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2025-08-16 13:34:22.448372: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2025-08-16 13:34:23.919317: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2025-08-16 13:34:24.018311: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# --- Load original model and tokenizer ---\n",
    "model_name = \"unitary/toxic-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5171d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define the TF Module with the correct signature ---\n",
    "class ToxicBertModule(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    # This signature with [None, None] is key for dynamic batch and sequence length\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=[None, None], dtype=tf.int32, name='input_ids'),\n",
    "        tf.TensorSpec(shape=[None, None], dtype=tf.int32, name='attention_mask')\n",
    "    ])\n",
    "    def __call__(self, input_ids, attention_mask):\n",
    "        # The output must be a dictionary\n",
    "        return {'logits': self.model(input_ids=input_ids, attention_mask=attention_mask).logits}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee43176d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_dynamic/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_dynamic/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SavedModel with dynamic signature created.\n"
     ]
    }
   ],
   "source": [
    "# --- Save the SavedModel ---\n",
    "serving_module = ToxicBertModule(model)\n",
    "tf.saved_model.save(serving_module, \"saved_model_dynamic\")\n",
    "\n",
    "print(\"SavedModel with dynamic signature created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775cc172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Convert to TFLite with settings to preserve dynamic shapes ---\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model_dynamic\")\n",
    "\n",
    "# IMPORTANT: Enable TF ops to handle operations not native to TFLite (common for BERT)\n",
    "# This is crucial for keeping dynamic shapes.\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS    # Enable TensorFlow ops.\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f33a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 13:35:45.023301: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-08-16 13:35:45.023358: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-08-16 13:35:45.024274: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: saved_model_dynamic\n",
      "2025-08-16 13:35:45.100892: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-08-16 13:35:45.100943: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: saved_model_dynamic\n",
      "2025-08-16 13:35:45.234609: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2025-08-16 13:35:45.260071: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-08-16 13:35:46.113978: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: saved_model_dynamic\n",
      "2025-08-16 13:35:46.350866: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 1326605 microseconds.\n",
      "2025-08-16 13:35:46.641906: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 222, Total Ops 1342, % non-converted = 16.54 %\n",
      " * 222 ARITH ops\n",
      "\n",
      "- arith.constant:  222 occurrences  (f32: 206, i32: 16)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 172)\n",
      "  (f32: 24)\n",
      "  (f32: 1)\n",
      "  (i32: 48)\n",
      "  (i32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 74)\n",
      "  (f32: 3, i32: 96)\n",
      "  (f32: 12)\n",
      "  (f32: 50)\n",
      "  (f32: 88)\n",
      "\n",
      "  (i32: 74)\n",
      "  (i32: 1)\n",
      "  (i32: 96)\n",
      "  (f32: 168, i32: 1)\n",
      "  (f32: 25)\n",
      "  (i32: 51)\n",
      "  (f32: 12)\n",
      "  (f32: 25)\n",
      "  (f32: 1, i32: 17)\n",
      "  (f32: 26)\n",
      "  (f32: 1)\n",
      "  (f32: 48)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Dynamic TFLite model saved as toxic_bert_dynamic.tflite\n"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "tflite_model_dynamic = converter.convert()\n",
    "\n",
    "# Save the new TFLite file\n",
    "with open(\"toxic_bert_dynamic.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model_dynamic)\n",
    "\n",
    "print(\"SUCCESS: Dynamic TFLite model saved as toxic_bert_dynamic.tflite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freelance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
